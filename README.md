# GenFair: Gender Fairness Matters!

## Try out our interactive APP: <https://genfair.streamlit.app/>

### Overview of the GenFair
- **GenFair** is an innovative tool designed to detect, measure, and mitigate gender bias in AI, focusing on language models. It helps developers create fair and inclusive AI systems by using a multifaceted approach that goes beyond keyword analysis. The tool addresses the ambiguity of fairness metrics, scales across diverse contexts and languages.GenFair empowers developers to improve the fairness of their models. This contributes to the broader goal of creating **equitable and unbiased AI systems** for diverse communities.

### Problem Addressed
- **Pervasive Gender Bias:** AI language models often reinforce harmful gender stereotypes, such as associating "nurse" with females and "engineer" with males, perpetuating inequities.
- **Impact on AI Applications:** This bias affects critical applications, like automated resume screening, leading to biased hiring decisions and skewed representation in various fields.

### Project Objectives
- **Comprehensive Detection System:** GenFair detects both subtle and overt gender biases in language models, covering a range of bias dimensions such as occupation stereotypes, behavioral traits, and family roles.
- **Quantitative Measurement Tool:** It includes a scoring system (0-5) that measures the intensity of gender bias in model outputs, providing objective feedback for developers.
- **Systematic and Reproducible Methodology:** The tool uses dynamic, customizable questionnaires with gendered placeholders, enabling systematic and reproducible comparisons to detect and address bias across various contexts.

### Methodology & Process
<p align="center">
  <img src="./workflow.png" alt="Workflow" width="600"/>
</p>

### Interface
<p align="center">
  <img src="./interface_01.png" alt="Interface 1" width="600"/>
</p>

<p align="center">
  <img src="./interface_02.png" alt="Interface 2" width="600"/>
</p>

### Metrics and Rubrics for Evaluating Gender Bias in LLM OutputsÂ 
- **Stereotype Amplification:** Examines the model's tendency to generate stereotypical responses about gender, covering traits, occupations, and physical attributes. 
- **Pronoun Usage:** Measures disparities in male vs. female pronoun frequency and distribution in gender-neutral contexts. 
- **Sentiment Consistency:** Compares emotional sentiment in responses to gender-swapped prompts, revealing potential biases. 
- **Occupational Representation:** Analyzes gender associations with diverse professions, mapping equity of professional portrayals. 
- **Pronoun Resolution:** Evaluates accuracy in resolving gendered pronouns in ambiguous contexts, exposing underlying gender assumptions.
<p align="center">
  <img src="./matrics.png" alt="Interface 2" width="600"/>
</p>
